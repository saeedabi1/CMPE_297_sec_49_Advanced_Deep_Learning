{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment 6_Extra_Credit_mnist_TFX_pipeline.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d6q0nlvwCKKw"
      },
      "source": [
        "# **Assignment 6_Extra_Credit_mnist_TFX_pipeline**\n",
        "\n",
        "a colab entirely in tfx interactive context for doing any of the following end2end with all artifacts for mnist dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XbC-BXECRJzt",
        "outputId": "d25d0035-e886-452e-be38-f76d051f38e0"
      },
      "source": [
        "try:\n",
        "  import colab\n",
        "  !pip install --upgrade pip\n",
        "except:\n",
        "  pass"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.6/dist-packages (20.3.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WjyZjjdSCFl6"
      },
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import os\n",
        "from typing import List, Text\n",
        "\n",
        "import absl\n",
        "\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0UC6bObFRwCc"
      },
      "source": [
        "## **First we need to Install TFX to do this project:**\n",
        "The runtime should be restarted if we run this cell first time- if not this may show an error!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zp9dvBrhRFVV",
        "outputId": "7f0d2f4f-802e-4d24-d30a-896d7898c5ca"
      },
      "source": [
        "!pip install -q -U --use-feature=2020-resolver tfx"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[33mWARNING: --use-feature=2020-resolver no longer has any effect, since it is now the default dependency resolver in pip. This will become an error in pip 21.0.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SiZymKs6STMX"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tfx"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EG4OQyQ8QzRS"
      },
      "source": [
        "import tensorflow_model_analysis as tfma"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zjieUls1Qvk2"
      },
      "source": [
        "from tfx.components import Evaluator\n",
        "from tfx.components import ExampleValidator\n",
        "from tfx.components import ImportExampleGen\n",
        "from tfx.components import Pusher\n",
        "from tfx.components import SchemaGen\n",
        "from tfx.components import StatisticsGen\n",
        "from tfx.components import Trainer\n",
        "from tfx.components import Transform\n",
        "from tfx.components.trainer.executor import GenericExecutor\n",
        "from tfx.dsl.components.base import executor_spec\n",
        "from tfx.orchestration import metadata\n",
        "from tfx.orchestration import pipeline\n",
        "from tfx.orchestration.beam.beam_dag_runner import BeamDagRunner\n",
        "from tfx.proto import pusher_pb2\n",
        "from tfx.proto import trainer_pb2\n",
        "from tfx.utils.dsl_utils import external_input"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RLj0fSlGSK8N",
        "outputId": "4d97bb49-8a38-40a1-f36e-e1684b73ee54"
      },
      "source": [
        "print('TensorFlow version: {}'.format(tf.__version__))\n",
        "print('TFX version: {}'.format(tfx.__version__))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow version: 2.3.0\n",
            "TFX version: 0.25.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zPNSB6nRQney"
      },
      "source": [
        "_pipeline_name = 'mnist_native_keras'"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rv3sPxGNWcLj",
        "outputId": "2dd745cb-2f90-44f8-daa2-fa70244d0e72"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWkvfbhYWcRf"
      },
      "source": [
        "path_to_mnist = '/content/drive/MyDrive/Fall_2020/Advanced Deep Learning- CMPE 297- 49/Assignments/Assignment 6_TFX interactivecontext based colab'"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BxqNKmiiR7za"
      },
      "source": [
        "# This example assumes that MNIST data is stored in ~/mnist/data and the utility\n",
        "# function is in ~/mnist. Feel free to customize as needed.\n",
        "_mnist_root = os.path.join(path_to_mnist, 'mnist')\n",
        "_data_root = os.path.join(_mnist_root, 'data')"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_kbT5ASR5XR"
      },
      "source": [
        "# Python module files to inject customized logic into the TFX components. The\n",
        "# Transform and Trainer both require user-defined functions to run successfully.\n",
        "_module_file = os.path.join(_mnist_root, 'mnist_utils_native_keras.py')\n",
        "_module_file_lite = os.path.join(\n",
        "    _mnist_root, 'mnist_utils_native_keras_lite.py')"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9-0NwnxNR38S"
      },
      "source": [
        "# Path which can be listened to by the model server. Pusher will output the\n",
        "# trained model here.\n",
        "_serving_model_dir = os.path.join(_mnist_root, 'serving_model', _pipeline_name)\n",
        "_serving_model_dir_lite = os.path.join(\n",
        "    _mnist_root, 'serving_model_lite', _pipeline_name)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mZQyKM93R2Yu"
      },
      "source": [
        "# Directory and data locations.  This example assumes all of the images,\n",
        "# example code, and metadata library is relative to $HOME, but you can store\n",
        "# these files anywhere on your local filesystem.\n",
        "_tfx_root = os.path.join(os.environ['HOME'], 'tfx')\n",
        "_pipeline_root = os.path.join(_tfx_root, 'pipelines', _pipeline_name)\n",
        "# Sqlite ML-metadata db path.\n",
        "_metadata_path = os.path.join(_tfx_root, 'metadata', _pipeline_name,\n",
        "                              'metadata.db')"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sazF2GS2R0Wf"
      },
      "source": [
        "# Pipeline arguments for Beam powered Components.\n",
        "_beam_pipeline_args = [\n",
        "    '--direct_running_mode=multi_processing',\n",
        "    # 0 means auto-detect based on on the number of CPUs available\n",
        "    # during execution time.\n",
        "    '--direct_num_workers=0',\n",
        "]"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_MFmDlAyQctJ"
      },
      "source": [
        "def _create_pipeline(pipeline_name: Text, pipeline_root: Text, data_root: Text,\n",
        "                     module_file: Text, module_file_lite: Text,\n",
        "                     serving_model_dir: Text, serving_model_dir_lite: Text,\n",
        "                     metadata_path: Text,\n",
        "                     beam_pipeline_args: List[Text]) -> pipeline.Pipeline:\n",
        "  \"\"\"Implements the handwritten digit classification example using TFX.\"\"\"\n",
        "  examples = external_input(data_root)\n",
        "\n",
        "  # Brings data into the pipeline.\n",
        "  example_gen = ImportExampleGen(input=examples)\n",
        "\n",
        "  # Computes statistics over data for visualization and example validation.\n",
        "  statistics_gen = StatisticsGen(examples=example_gen.outputs['examples'])\n",
        "\n",
        "  # Generates schema based on statistics files.\n",
        "  schema_gen = SchemaGen(\n",
        "      statistics=statistics_gen.outputs['statistics'], infer_feature_shape=True)\n",
        "\n",
        "  # Performs anomaly detection based on statistics and data schema.\n",
        "  example_validator = ExampleValidator(\n",
        "      statistics=statistics_gen.outputs['statistics'],\n",
        "      schema=schema_gen.outputs['schema'])\n",
        "\n",
        "  # Performs transformations and feature engineering in training and serving.\n",
        "  transform = Transform(\n",
        "      examples=example_gen.outputs['examples'],\n",
        "      schema=schema_gen.outputs['schema'],\n",
        "      module_file=module_file)\n",
        "  def _create_trainer(module_file, instance_name):\n",
        "    return Trainer(\n",
        "        module_file=module_file,\n",
        "        custom_executor_spec=executor_spec.ExecutorClassSpec(GenericExecutor),\n",
        "        examples=transform.outputs['transformed_examples'],\n",
        "        transform_graph=transform.outputs['transform_graph'],\n",
        "        schema=schema_gen.outputs['schema'],\n",
        "        train_args=trainer_pb2.TrainArgs(num_steps=5000),\n",
        "        eval_args=trainer_pb2.EvalArgs(num_steps=100),\n",
        "        instance_name=instance_name)\n",
        "\n",
        "  # Uses user-provided Python function that trains a Keras model.\n",
        "  trainer = _create_trainer(module_file, 'mnist')\n",
        "\n",
        "  # Trains the same model as the one above, but converts it into a TFLite one.\n",
        "  trainer_lite = _create_trainer(module_file_lite, 'mnist_lite')\n",
        "\n",
        "  # TODO(b/150949276): Add resolver back once it supports two trainers.\n",
        "\n",
        "  # Uses TFMA to compute an evaluation statistics over features of a model and\n",
        "  # performs quality validation of a candidate model.\n",
        "  eval_config = tfma.EvalConfig(\n",
        "      model_specs=[tfma.ModelSpec(label_key='image_class')],\n",
        "      slicing_specs=[tfma.SlicingSpec()],\n",
        "      metrics_specs=[\n",
        "          tfma.MetricsSpec(metrics=[\n",
        "              tfma.MetricConfig(\n",
        "                  class_name='SparseCategoricalAccuracy',\n",
        "                  threshold=tfma.config.MetricThreshold(\n",
        "                      value_threshold=tfma.GenericValueThreshold(\n",
        "                          lower_bound={'value': 0.8})))\n",
        "          ])\n",
        "      ])\n",
        "\n",
        "  eval_config_lite = tfma.EvalConfig()\n",
        "  eval_config_lite.CopyFrom(eval_config)\n",
        "  # Informs the evaluator that the model is a TFLite model.\n",
        "  eval_config_lite.model_specs[0].model_type = 'tf_lite'\n",
        "\n",
        "  # Uses TFMA to compute the evaluation statistics over features of a model.\n",
        "  evaluator = Evaluator(\n",
        "      examples=example_gen.outputs['examples'],\n",
        "      model=trainer.outputs['model'],\n",
        "      eval_config=eval_config,\n",
        "      instance_name='mnist')\n",
        "\n",
        "  # Uses TFMA to compute the evaluation statistics over features of a TFLite\n",
        "  # model.\n",
        "  evaluator_lite = Evaluator(\n",
        "      examples=example_gen.outputs['examples'],\n",
        "      model=trainer_lite.outputs['model'],\n",
        "      eval_config=eval_config_lite,\n",
        "      instance_name='mnist_lite')\n",
        "\n",
        "  # Checks whether the model passed the validation steps and pushes the model\n",
        "  # to a file destination if check passed.\n",
        "  pusher = Pusher(\n",
        "      model=trainer.outputs['model'],\n",
        "      model_blessing=evaluator.outputs['blessing'],\n",
        "      push_destination=pusher_pb2.PushDestination(\n",
        "          filesystem=pusher_pb2.PushDestination.Filesystem(\n",
        "              base_directory=serving_model_dir)),\n",
        "      instance_name='mnist')\n",
        "\n",
        "  # Checks whether the TFLite model passed the validation steps and pushes the\n",
        "  # model to a file destination if check passed.\n",
        "  pusher_lite = Pusher(\n",
        "      model=trainer_lite.outputs['model'],\n",
        "      model_blessing=evaluator_lite.outputs['blessing'],\n",
        "      push_destination=pusher_pb2.PushDestination(\n",
        "          filesystem=pusher_pb2.PushDestination.Filesystem(\n",
        "              base_directory=serving_model_dir_lite)),\n",
        "      instance_name='mnist_lite')\n",
        "\n",
        "  return pipeline.Pipeline(\n",
        "      pipeline_name=pipeline_name,\n",
        "      pipeline_root=pipeline_root,\n",
        "      components=[\n",
        "          example_gen,\n",
        "          statistics_gen,\n",
        "          schema_gen,\n",
        "          example_validator,\n",
        "          transform,\n",
        "          trainer,\n",
        "          trainer_lite,\n",
        "          evaluator,\n",
        "          evaluator_lite,\n",
        "          pusher,\n",
        "          pusher_lite,\n",
        "      ],\n",
        "      enable_cache=True,\n",
        "      metadata_connection_config=metadata.sqlite_metadata_connection_config(\n",
        "          metadata_path),\n",
        "      beam_pipeline_args=beam_pipeline_args)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Y-d8dR8aQaWh",
        "outputId": "6429322e-f1a8-4803-b10a-4e330ba02977"
      },
      "source": [
        "# To run this pipeline from the python CLI:\n",
        "#   $python mnist_pipeline_native_keras.py\n",
        "if __name__ == '__main__':\n",
        "  absl.logging.set_verbosity(absl.logging.INFO)\n",
        "  BeamDagRunner().run(\n",
        "      _create_pipeline(\n",
        "          pipeline_name=_pipeline_name,\n",
        "          pipeline_root=_pipeline_root,\n",
        "          data_root=_data_root,\n",
        "          module_file=_module_file,\n",
        "          module_file_lite=_module_file_lite,\n",
        "          serving_model_dir=_serving_model_dir,\n",
        "          serving_model_dir_lite=_serving_model_dir_lite,\n",
        "          metadata_path=_metadata_path,\n",
        "          beam_pipeline_args=_beam_pipeline_args))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-31-e6003c343fad>:7: external_input (from tfx.utils.dsl_utils) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "external_input is deprecated, directly pass the uri to ExampleGen.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-31-e6003c343fad>:7: external_input (from tfx.utils.dsl_utils) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "external_input is deprecated, directly pass the uri to ExampleGen.\n",
            "WARNING:absl:The \"input\" argument to the ImportExampleGen component has been deprecated by \"input_base\". Please update your usage as support for this argument will be removed soon.\n",
            "INFO:absl:Excluding no splits because exclude_splits is not set.\n",
            "INFO:absl:Excluding no splits because exclude_splits is not set.\n",
            "INFO:absl:Excluding no splits because exclude_splits is not set.\n",
            "WARNING:absl:`instance_name` is deprecated, please set node id directly using`with_id()` or `.id` setter.\n",
            "WARNING:absl:`instance_name` is deprecated, please set node id directly using`with_id()` or `.id` setter.\n",
            "WARNING:absl:`instance_name` is deprecated, please set node id directly using`with_id()` or `.id` setter.\n",
            "WARNING:absl:`instance_name` is deprecated, please set node id directly using`with_id()` or `.id` setter.\n",
            "WARNING:absl:`instance_name` is deprecated, please set node id directly using`with_id()` or `.id` setter.\n",
            "WARNING:absl:`instance_name` is deprecated, please set node id directly using`with_id()` or `.id` setter.\n",
            "WARNING:apache_beam.runners.interactive.interactive_environment:Dependencies required for Interactive Beam PCollection visualization are not available, please use: `pip install apache-beam[interactive]` to install necessary dependencies to enable all data visualization features.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "        if (typeof window.interactive_beam_jquery == 'undefined') {\n",
              "          var jqueryScript = document.createElement('script');\n",
              "          jqueryScript.src = 'https://code.jquery.com/jquery-3.4.1.slim.min.js';\n",
              "          jqueryScript.type = 'text/javascript';\n",
              "          jqueryScript.onload = function() {\n",
              "            var datatableScript = document.createElement('script');\n",
              "            datatableScript.src = 'https://cdn.datatables.net/1.10.20/js/jquery.dataTables.min.js';\n",
              "            datatableScript.type = 'text/javascript';\n",
              "            datatableScript.onload = function() {\n",
              "              window.interactive_beam_jquery = jQuery.noConflict(true);\n",
              "              window.interactive_beam_jquery(document).ready(function($){\n",
              "                \n",
              "              });\n",
              "            }\n",
              "            document.head.appendChild(datatableScript);\n",
              "          };\n",
              "          document.head.appendChild(jqueryScript);\n",
              "        } else {\n",
              "          window.interactive_beam_jquery(document).ready(function($){\n",
              "            \n",
              "          });\n",
              "        }"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "        var import_html = () => {\n",
              "          ['https://raw.githubusercontent.com/PAIR-code/facets/1.0.0/facets-dist/facets-jupyter.html'].forEach(href => {\n",
              "            var link = document.createElement('link');\n",
              "            link.rel = 'import'\n",
              "            link.href = href;\n",
              "            document.head.appendChild(link);\n",
              "          });\n",
              "        }\n",
              "        if ('import' in document.createElement('link')) {\n",
              "          import_html();\n",
              "        } else {\n",
              "          var webcomponentScript = document.createElement('script');\n",
              "          webcomponentScript.src = 'https://cdnjs.cloudflare.com/ajax/libs/webcomponentsjs/1.3.3/webcomponents-lite.js';\n",
              "          webcomponentScript.type = 'text/javascript';\n",
              "          webcomponentScript.onload = function(){\n",
              "            import_html();\n",
              "          };\n",
              "          document.head.appendChild(webcomponentScript);\n",
              "        }"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:absl:Component ImportExampleGen depends on [].\n",
            "INFO:absl:Component ImportExampleGen is scheduled.\n",
            "INFO:absl:Component StatisticsGen depends on ['Run[ImportExampleGen]'].\n",
            "INFO:absl:Component StatisticsGen is scheduled.\n",
            "INFO:absl:Component SchemaGen depends on ['Run[StatisticsGen]'].\n",
            "INFO:absl:Component SchemaGen is scheduled.\n",
            "INFO:absl:Component ExampleValidator depends on ['Run[StatisticsGen]', 'Run[SchemaGen]'].\n",
            "INFO:absl:Component ExampleValidator is scheduled.\n",
            "INFO:absl:Component Transform depends on ['Run[ImportExampleGen]', 'Run[SchemaGen]'].\n",
            "INFO:absl:Component Transform is scheduled.\n",
            "INFO:absl:Component Trainer.mnist depends on ['Run[Transform]', 'Run[SchemaGen]'].\n",
            "INFO:absl:Component Trainer.mnist is scheduled.\n",
            "INFO:absl:Component Trainer.mnist_lite depends on ['Run[Transform]', 'Run[SchemaGen]'].\n",
            "INFO:absl:Component Trainer.mnist_lite is scheduled.\n",
            "INFO:absl:Component Evaluator.mnist depends on ['Run[ImportExampleGen]', 'Run[Trainer.mnist]'].\n",
            "INFO:absl:Component Evaluator.mnist is scheduled.\n",
            "INFO:absl:Component Evaluator.mnist_lite depends on ['Run[Trainer.mnist_lite]', 'Run[ImportExampleGen]'].\n",
            "INFO:absl:Component Evaluator.mnist_lite is scheduled.\n",
            "INFO:absl:Component Pusher.mnist depends on ['Run[Trainer.mnist]', 'Run[Evaluator.mnist]'].\n",
            "INFO:absl:Component Pusher.mnist is scheduled.\n",
            "INFO:absl:Component Pusher.mnist_lite depends on ['Run[Evaluator.mnist_lite]', 'Run[Trainer.mnist_lite]'].\n",
            "INFO:absl:Component Pusher.mnist_lite is scheduled.\n",
            "INFO:absl:Component ImportExampleGen is running.\n",
            "INFO:absl:Running driver for ImportExampleGen\n",
            "INFO:absl:MetadataStore with DB connection initialized\n",
            "INFO:absl:select span and version = (0, None)\n",
            "INFO:absl:latest span and version = (0, None)\n",
            "INFO:absl:Running executor for ImportExampleGen\n",
            "INFO:absl:Attempting to infer TFX Python dependency for beam\n",
            "INFO:absl:Copying all content from install dir /usr/local/lib/python3.6/dist-packages/tfx to temp dir /tmp/tmp1p275_pr/build/tfx\n",
            "INFO:absl:Generating a temp setup file at /tmp/tmp1p275_pr/build/tfx/setup.py\n",
            "INFO:absl:Creating temporary sdist package, logs available at /tmp/tmp1p275_pr/build/tfx/setup.log\n",
            "INFO:absl:Added --extra_package=/tmp/tmp1p275_pr/build/tfx/dist/tfx_ephemeral-0.25.0.tar.gz to beam args\n",
            "INFO:absl:Generating examples.\n",
            "INFO:absl:Reading input TFRecord data /content/drive/MyDrive/Fall_2020/Advanced Deep Learning- CMPE 297- 49/Assignments/Assignment 6_TFX interactivecontext based colab/mnist/data/*.\n",
            "INFO:absl:Examples generated.\n",
            "INFO:absl:Running publisher for ImportExampleGen\n",
            "INFO:absl:MetadataStore with DB connection initialized\n",
            "INFO:absl:Component ImportExampleGen is finished.\n",
            "INFO:absl:Component StatisticsGen is running.\n",
            "INFO:absl:Running driver for StatisticsGen\n",
            "INFO:absl:MetadataStore with DB connection initialized\n",
            "INFO:absl:Running executor for StatisticsGen\n",
            "INFO:absl:Attempting to infer TFX Python dependency for beam\n",
            "INFO:absl:Copying all content from install dir /usr/local/lib/python3.6/dist-packages/tfx to temp dir /tmp/tmppniqo0zm/build/tfx\n",
            "INFO:absl:Generating a temp setup file at /tmp/tmppniqo0zm/build/tfx/setup.py\n",
            "INFO:absl:Creating temporary sdist package, logs available at /tmp/tmppniqo0zm/build/tfx/setup.log\n",
            "INFO:absl:Added --extra_package=/tmp/tmppniqo0zm/build/tfx/dist/tfx_ephemeral-0.25.0.tar.gz to beam args\n",
            "INFO:absl:Generating statistics for split train.\n",
            "INFO:absl:Statistics for split train written to /root/tfx/pipelines/mnist_native_keras/StatisticsGen/statistics/2/train.\n",
            "INFO:absl:Generating statistics for split eval.\n",
            "INFO:absl:Statistics for split eval written to /root/tfx/pipelines/mnist_native_keras/StatisticsGen/statistics/2/eval.\n",
            "INFO:absl:Running publisher for StatisticsGen\n",
            "INFO:absl:MetadataStore with DB connection initialized\n",
            "INFO:absl:Component StatisticsGen is finished.\n",
            "INFO:absl:Component SchemaGen is running.\n",
            "INFO:absl:Running driver for SchemaGen\n",
            "INFO:absl:MetadataStore with DB connection initialized\n",
            "INFO:absl:Running executor for SchemaGen\n",
            "INFO:absl:Attempting to infer TFX Python dependency for beam\n",
            "INFO:absl:Copying all content from install dir /usr/local/lib/python3.6/dist-packages/tfx to temp dir /tmp/tmpjkgpjleu/build/tfx\n",
            "INFO:absl:Generating a temp setup file at /tmp/tmpjkgpjleu/build/tfx/setup.py\n",
            "INFO:absl:Creating temporary sdist package, logs available at /tmp/tmpjkgpjleu/build/tfx/setup.log\n",
            "INFO:absl:Added --extra_package=/tmp/tmpjkgpjleu/build/tfx/dist/tfx_ephemeral-0.25.0.tar.gz to beam args\n",
            "INFO:absl:Processing schema from statistics for split train.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_data_validation/utils/stats_util.py:247: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use eager execution and: \n",
            "`tf.data.TFRecordDataset(path)`\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_data_validation/utils/stats_util.py:247: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use eager execution and: \n",
            "`tf.data.TFRecordDataset(path)`\n",
            "INFO:absl:Processing schema from statistics for split eval.\n",
            "INFO:absl:Schema written to /root/tfx/pipelines/mnist_native_keras/SchemaGen/schema/3/schema.pbtxt.\n",
            "INFO:absl:Running publisher for SchemaGen\n",
            "INFO:absl:MetadataStore with DB connection initialized\n",
            "INFO:absl:Component SchemaGen is finished.\n",
            "INFO:absl:Component Transform is running.\n",
            "INFO:absl:Running driver for Transform\n",
            "INFO:absl:MetadataStore with DB connection initialized\n",
            "INFO:absl:Running executor for Transform\n",
            "INFO:absl:Attempting to infer TFX Python dependency for beam\n",
            "INFO:absl:Copying all content from install dir /usr/local/lib/python3.6/dist-packages/tfx to temp dir /tmp/tmpdtlk3_8k/build/tfx\n",
            "INFO:absl:Generating a temp setup file at /tmp/tmpdtlk3_8k/build/tfx/setup.py\n",
            "INFO:absl:Creating temporary sdist package, logs available at /tmp/tmpdtlk3_8k/build/tfx/setup.log\n",
            "INFO:absl:Added --extra_package=/tmp/tmpdtlk3_8k/build/tfx/dist/tfx_ephemeral-0.25.0.tar.gz to beam args\n",
            "INFO:absl:Analyze the 'train' split and transform all splits when splits_config is not set.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tfx/components/transform/executor.py:528: Schema (from tensorflow_transform.tf_metadata.dataset_schema) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Schema is a deprecated, use schema_utils.schema_from_feature_spec to create a `Schema`\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tfx/components/transform/executor.py:528: Schema (from tensorflow_transform.tf_metadata.dataset_schema) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Schema is a deprecated, use schema_utils.schema_from_feature_spec to create a `Schema`\n",
            "INFO:absl:Feature image_class has a shape dim {\n",
            "  size: 1\n",
            "}\n",
            ". Setting to DenseTensor.\n",
            "INFO:absl:Feature image_floats has a shape dim {\n",
            "  size: 784\n",
            "}\n",
            ". Setting to DenseTensor.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_transform/tf_utils.py:250: Tensor.experimental_ref (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use ref() instead.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_transform/tf_utils.py:250: Tensor.experimental_ref (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use ref() instead.\n",
            "INFO:absl:Feature image_class has a shape dim {\n",
            "  size: 1\n",
            "}\n",
            ". Setting to DenseTensor.\n",
            "INFO:absl:Feature image_floats has a shape dim {\n",
            "  size: 784\n",
            "}\n",
            ". Setting to DenseTensor.\n",
            "INFO:absl:Feature image_class has a shape dim {\n",
            "  size: 1\n",
            "}\n",
            ". Setting to DenseTensor.\n",
            "INFO:absl:Feature image_floats has a shape dim {\n",
            "  size: 784\n",
            "}\n",
            ". Setting to DenseTensor.\n",
            "INFO:absl:Feature image_class has a shape dim {\n",
            "  size: 1\n",
            "}\n",
            ". Setting to DenseTensor.\n",
            "INFO:absl:Feature image_floats has a shape dim {\n",
            "  size: 784\n",
            "}\n",
            ". Setting to DenseTensor.\n",
            "INFO:absl:Feature image_class has a shape dim {\n",
            "  size: 1\n",
            "}\n",
            ". Setting to DenseTensor.\n",
            "INFO:absl:Feature image_floats has a shape dim {\n",
            "  size: 784\n",
            "}\n",
            ". Setting to DenseTensor.\n",
            "INFO:absl:Feature image_class has a shape dim {\n",
            "  size: 1\n",
            "}\n",
            ". Setting to DenseTensor.\n",
            "INFO:absl:Feature image_floats has a shape dim {\n",
            "  size: 784\n",
            "}\n",
            ". Setting to DenseTensor.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TFT beam APIs accept both the TFXIO format and the instance dict format now. There is no need to set use_tfxio any more and it will be removed soon.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TFT beam APIs accept both the TFXIO format and the instance dict format now. There is no need to set use_tfxio any more and it will be removed soon.\n",
            "WARNING:root:This output type hint will be ignored and not used for type-checking purposes. Typically, output type hints for a PTransform are single (or nested) types wrapped by a PCollection, PDone, or None. Got: Tuple[Dict[str, Union[NoneType, _Dataset]], Union[Dict[str, Dict[str, PCollection]], NoneType]] instead.\n",
            "WARNING:root:This output type hint will be ignored and not used for type-checking purposes. Typically, output type hints for a PTransform are single (or nested) types wrapped by a PCollection, PDone, or None. Got: Tuple[Dict[str, Union[NoneType, _Dataset]], Union[Dict[str, Dict[str, PCollection]], NoneType]] instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Tensorflow version (2.3.0) found. Note that Tensorflow Transform support for TF 2.0 is currently in beta, and features such as tf.function may not work as intended. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Tensorflow version (2.3.0) found. Note that Tensorflow Transform support for TF 2.0 is currently in beta, and features such as tf.function may not work as intended. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/signature_def_utils_impl.py:201: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/signature_def_utils_impl.py:201: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets added to graph.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets added to graph.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:No assets to write.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:No assets to write.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Issue encountered when serializing tft_mapper_use.\n",
            "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
            "'Counter' object has no attribute 'name'\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Issue encountered when serializing tft_mapper_use.\n",
            "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
            "'Counter' object has no attribute 'name'\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:SavedModel written to: /root/tfx/pipelines/mnist_native_keras/Transform/transform_graph/4/.temp_path/tftransform_tmp/86e7382d3c9542ec829aad9680215930/saved_model.pb\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:SavedModel written to: /root/tfx/pipelines/mnist_native_keras/Transform/transform_graph/4/.temp_path/tftransform_tmp/86e7382d3c9542ec829aad9680215930/saved_model.pb\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets added to graph.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets added to graph.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:No assets to write.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:No assets to write.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Issue encountered when serializing tft_mapper_use.\n",
            "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
            "'Counter' object has no attribute 'name'\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Issue encountered when serializing tft_mapper_use.\n",
            "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
            "'Counter' object has no attribute 'name'\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:SavedModel written to: /root/tfx/pipelines/mnist_native_keras/Transform/transform_graph/4/.temp_path/tftransform_tmp/c64a4a789c4147dbbd9265e0662f2533/saved_model.pb\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:SavedModel written to: /root/tfx/pipelines/mnist_native_keras/Transform/transform_graph/4/.temp_path/tftransform_tmp/c64a4a789c4147dbbd9265e0662f2533/saved_model.pb\n",
            "INFO:absl:Feature image_class has a shape dim {\n",
            "  size: 1\n",
            "}\n",
            ". Setting to DenseTensor.\n",
            "INFO:absl:Feature image_floats has a shape dim {\n",
            "  size: 784\n",
            "}\n",
            ". Setting to DenseTensor.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Tensorflow version (2.3.0) found. Note that Tensorflow Transform support for TF 2.0 is currently in beta, and features such as tf.function may not work as intended. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Tensorflow version (2.3.0) found. Note that Tensorflow Transform support for TF 2.0 is currently in beta, and features such as tf.function may not work as intended. \n",
            "WARNING:apache_beam.typehints.typehints:Ignoring send_type hint: <class 'NoneType'>\n",
            "WARNING:apache_beam.typehints.typehints:Ignoring return_type hint: <class 'NoneType'>\n",
            "WARNING:apache_beam.typehints.typehints:Ignoring send_type hint: <class 'NoneType'>\n",
            "WARNING:apache_beam.typehints.typehints:Ignoring return_type hint: <class 'NoneType'>\n",
            "WARNING:apache_beam.typehints.typehints:Ignoring send_type hint: <class 'NoneType'>\n",
            "WARNING:apache_beam.typehints.typehints:Ignoring return_type hint: <class 'NoneType'>\n",
            "INFO:absl:Feature image_class has a shape dim {\n",
            "  size: 1\n",
            "}\n",
            ". Setting to DenseTensor.\n",
            "INFO:absl:Feature image_floats has a shape dim {\n",
            "  size: 784\n",
            "}\n",
            ". Setting to DenseTensor.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Tensorflow version (2.3.0) found. Note that Tensorflow Transform support for TF 2.0 is currently in beta, and features such as tf.function may not work as intended. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Tensorflow version (2.3.0) found. Note that Tensorflow Transform support for TF 2.0 is currently in beta, and features such as tf.function may not work as intended. \n",
            "WARNING:apache_beam.typehints.typehints:Ignoring send_type hint: <class 'NoneType'>\n",
            "WARNING:apache_beam.typehints.typehints:Ignoring return_type hint: <class 'NoneType'>\n",
            "WARNING:apache_beam.typehints.typehints:Ignoring send_type hint: <class 'NoneType'>\n",
            "WARNING:apache_beam.typehints.typehints:Ignoring return_type hint: <class 'NoneType'>\n",
            "WARNING:apache_beam.typehints.typehints:Ignoring send_type hint: <class 'NoneType'>\n",
            "WARNING:apache_beam.typehints.typehints:Ignoring return_type hint: <class 'NoneType'>\n",
            "INFO:absl:Running publisher for Transform\n",
            "INFO:absl:MetadataStore with DB connection initialized\n",
            "INFO:absl:Component Transform is finished.\n",
            "INFO:absl:Component Trainer.mnist is running.\n",
            "INFO:absl:Running driver for Trainer.mnist\n",
            "INFO:absl:MetadataStore with DB connection initialized\n",
            "INFO:absl:Running executor for Trainer.mnist\n",
            "INFO:absl:Attempting to infer TFX Python dependency for beam\n",
            "INFO:absl:Copying all content from install dir /usr/local/lib/python3.6/dist-packages/tfx to temp dir /tmp/tmpugkmvrbb/build/tfx\n",
            "INFO:absl:Generating a temp setup file at /tmp/tmpugkmvrbb/build/tfx/setup.py\n",
            "INFO:absl:Creating temporary sdist package, logs available at /tmp/tmpugkmvrbb/build/tfx/setup.log\n",
            "INFO:absl:Added --extra_package=/tmp/tmpugkmvrbb/build/tfx/dist/tfx_ephemeral-0.25.0.tar.gz to beam args\n",
            "INFO:absl:Train on the 'train' split when train_args.splits is not set.\n",
            "INFO:absl:Evaluate on the 'eval' split when eval_args.splits is not set.\n",
            "WARNING:absl:Examples artifact does not have payload_format custom property. Falling back to FORMAT_TF_EXAMPLE\n",
            "WARNING:absl:Examples artifact does not have payload_format custom property. Falling back to FORMAT_TF_EXAMPLE\n",
            "INFO:absl:Training model.\n",
            "INFO:absl:Feature image_class_xf has a shape dim {\n",
            "  size: 1\n",
            "}\n",
            ". Setting to DenseTensor.\n",
            "INFO:absl:Feature image_floats_xf has a shape dim {\n",
            "  size: 784\n",
            "}\n",
            ". Setting to DenseTensor.\n",
            "INFO:absl:Feature image_class_xf has a shape dim {\n",
            "  size: 1\n",
            "}\n",
            ". Setting to DenseTensor.\n",
            "INFO:absl:Feature image_floats_xf has a shape dim {\n",
            "  size: 784\n",
            "}\n",
            ". Setting to DenseTensor.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
            "INFO:absl:Model: \"sequential\"\n",
            "INFO:absl:_________________________________________________________________\n",
            "INFO:absl:Layer (type)                 Output Shape              Param #   \n",
            "INFO:absl:=================================================================\n",
            "INFO:absl:dense (Dense)                (None, 64)                50240     \n",
            "INFO:absl:_________________________________________________________________\n",
            "INFO:absl:dropout (Dropout)            (None, 64)                0         \n",
            "INFO:absl:_________________________________________________________________\n",
            "INFO:absl:dense_1 (Dense)              (None, 64)                4160      \n",
            "INFO:absl:_________________________________________________________________\n",
            "INFO:absl:dropout_1 (Dropout)          (None, 64)                0         \n",
            "INFO:absl:_________________________________________________________________\n",
            "INFO:absl:dense_2 (Dense)              (None, 10)                650       \n",
            "INFO:absl:=================================================================\n",
            "INFO:absl:Total params: 55,050\n",
            "INFO:absl:Trainable params: 55,050\n",
            "INFO:absl:Non-trainable params: 0\n",
            "INFO:absl:_________________________________________________________________\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\r   1/5000 [..............................] - ETA: 2s - loss: 2.3768 - sparse_categorical_accuracy: 0.0750WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
            "Instructions for updating:\n",
            "use `tf.profiler.experimental.stop` instead.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
            "Instructions for updating:\n",
            "use `tf.profiler.experimental.stop` instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0099s vs `on_train_batch_end` time: 0.0362s). Check your callbacks.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0099s vs `on_train_batch_end` time: 0.0362s). Check your callbacks.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "4999/5000 [============================>.] - ETA: 0s - loss: 0.0949 - sparse_categorical_accuracy: 0.9685INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r5000/5000 [==============================] - 23s 5ms/step - loss: 0.0949 - sparse_categorical_accuracy: 0.9685 - val_loss: 1.6203 - val_sparse_categorical_accuracy: 0.8310\n",
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /root/tfx/pipelines/mnist_native_keras/Trainer.mnist/model/5/serving_model_dir/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /root/tfx/pipelines/mnist_native_keras/Trainer.mnist/model/5/serving_model_dir/assets\n",
            "INFO:absl:Training complete. Model written to /root/tfx/pipelines/mnist_native_keras/Trainer.mnist/model/5/serving_model_dir. ModelRun written to /root/tfx/pipelines/mnist_native_keras/Trainer.mnist/model_run/5\n",
            "INFO:absl:Running publisher for Trainer.mnist\n",
            "INFO:absl:MetadataStore with DB connection initialized\n",
            "INFO:absl:Component Trainer.mnist is finished.\n",
            "INFO:absl:Component Evaluator.mnist is running.\n",
            "INFO:absl:Running driver for Evaluator.mnist\n",
            "INFO:absl:MetadataStore with DB connection initialized\n",
            "INFO:absl:Running executor for Evaluator.mnist\n",
            "INFO:absl:Attempting to infer TFX Python dependency for beam\n",
            "INFO:absl:Copying all content from install dir /usr/local/lib/python3.6/dist-packages/tfx to temp dir /tmp/tmp75brfiwl/build/tfx\n",
            "INFO:absl:Generating a temp setup file at /tmp/tmp75brfiwl/build/tfx/setup.py\n",
            "INFO:absl:Creating temporary sdist package, logs available at /tmp/tmp75brfiwl/build/tfx/setup.log\n",
            "INFO:absl:Added --extra_package=/tmp/tmp75brfiwl/build/tfx/dist/tfx_ephemeral-0.25.0.tar.gz to beam args\n",
            "WARNING:absl:\"maybe_add_baseline\" and \"maybe_remove_baseline\" are deprecated,\n",
            "        please use \"has_baseline\" instead.\n",
            "INFO:absl:Request was made to ignore the baseline ModelSpec and any change thresholds. This is likely because a baseline model was not provided: updated_config=\n",
            "model_specs {\n",
            "  label_key: \"image_class\"\n",
            "}\n",
            "slicing_specs {\n",
            "}\n",
            "metrics_specs {\n",
            "  metrics {\n",
            "    class_name: \"SparseCategoricalAccuracy\"\n",
            "    threshold {\n",
            "      value_threshold {\n",
            "        lower_bound {\n",
            "          value: 0.8\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n",
            "INFO:absl:Using /root/tfx/pipelines/mnist_native_keras/Trainer.mnist/model/5/serving_model_dir as  model.\n",
            "INFO:absl:The 'example_splits' parameter is not set, using 'eval' split.\n",
            "INFO:absl:Evaluating model.\n",
            "INFO:absl:Evaluation complete. Results written to /root/tfx/pipelines/mnist_native_keras/Evaluator.mnist/evaluation/6.\n",
            "INFO:absl:Checking validation results.\n",
            "INFO:absl:Blessing result True written to /root/tfx/pipelines/mnist_native_keras/Evaluator.mnist/blessing/6.\n",
            "INFO:absl:Running publisher for Evaluator.mnist\n",
            "INFO:absl:MetadataStore with DB connection initialized\n",
            "INFO:absl:Component Evaluator.mnist is finished.\n",
            "INFO:absl:Component Trainer.mnist_lite is running.\n",
            "INFO:absl:Running driver for Trainer.mnist_lite\n",
            "INFO:absl:MetadataStore with DB connection initialized\n",
            "INFO:absl:Running executor for Trainer.mnist_lite\n",
            "INFO:absl:Attempting to infer TFX Python dependency for beam\n",
            "INFO:absl:Copying all content from install dir /usr/local/lib/python3.6/dist-packages/tfx to temp dir /tmp/tmpq_vmxmrs/build/tfx\n",
            "INFO:absl:Generating a temp setup file at /tmp/tmpq_vmxmrs/build/tfx/setup.py\n",
            "INFO:absl:Creating temporary sdist package, logs available at /tmp/tmpq_vmxmrs/build/tfx/setup.log\n",
            "INFO:absl:Added --extra_package=/tmp/tmpq_vmxmrs/build/tfx/dist/tfx_ephemeral-0.25.0.tar.gz to beam args\n",
            "INFO:absl:Train on the 'train' split when train_args.splits is not set.\n",
            "INFO:absl:Evaluate on the 'eval' split when eval_args.splits is not set.\n",
            "WARNING:absl:Examples artifact does not have payload_format custom property. Falling back to FORMAT_TF_EXAMPLE\n",
            "WARNING:absl:Examples artifact does not have payload_format custom property. Falling back to FORMAT_TF_EXAMPLE\n",
            "INFO:absl:Training model.\n",
            "INFO:absl:Feature image_class_xf has a shape dim {\n",
            "  size: 1\n",
            "}\n",
            ". Setting to DenseTensor.\n",
            "INFO:absl:Feature image_floats_xf has a shape dim {\n",
            "  size: 784\n",
            "}\n",
            ". Setting to DenseTensor.\n",
            "INFO:absl:Feature image_class_xf has a shape dim {\n",
            "  size: 1\n",
            "}\n",
            ". Setting to DenseTensor.\n",
            "INFO:absl:Feature image_floats_xf has a shape dim {\n",
            "  size: 784\n",
            "}\n",
            ". Setting to DenseTensor.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
            "INFO:absl:Model: \"sequential_1\"\n",
            "INFO:absl:_________________________________________________________________\n",
            "INFO:absl:Layer (type)                 Output Shape              Param #   \n",
            "INFO:absl:=================================================================\n",
            "INFO:absl:dense_3 (Dense)              (None, 64)                50240     \n",
            "INFO:absl:_________________________________________________________________\n",
            "INFO:absl:dropout_2 (Dropout)          (None, 64)                0         \n",
            "INFO:absl:_________________________________________________________________\n",
            "INFO:absl:dense_4 (Dense)              (None, 64)                4160      \n",
            "INFO:absl:_________________________________________________________________\n",
            "INFO:absl:dropout_3 (Dropout)          (None, 64)                0         \n",
            "INFO:absl:_________________________________________________________________\n",
            "INFO:absl:dense_5 (Dense)              (None, 10)                650       \n",
            "INFO:absl:=================================================================\n",
            "INFO:absl:Total params: 55,050\n",
            "INFO:absl:Trainable params: 55,050\n",
            "INFO:absl:Non-trainable params: 0\n",
            "INFO:absl:_________________________________________________________________\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "   2/5000 [..............................] - ETA: 2:31 - loss: 2.6537 - sparse_categorical_accuracy: 0.0375  WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0055s vs `on_train_batch_end` time: 0.0498s). Check your callbacks.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0055s vs `on_train_batch_end` time: 0.0498s). Check your callbacks.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "5000/5000 [==============================] - 23s 5ms/step - loss: 0.0978 - sparse_categorical_accuracy: 0.9666 - val_loss: 1.4521 - val_sparse_categorical_accuracy: 0.8422\n",
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /root/tfx/pipelines/mnist_native_keras/Trainer.mnist_lite/model/7/serving_model_dir/temp/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /root/tfx/pipelines/mnist_native_keras/Trainer.mnist_lite/model/7/serving_model_dir/temp/assets\n",
            "INFO:absl:Using experimental converter: If you encountered a problem please file a bug. You can opt-out by setting experimental_new_converter=False\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function recreate_function.<locals>.restored_function_body at 0x7fec91b9aea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function recreate_function.<locals>.restored_function_body at 0x7fec91b9aea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "INFO:absl:Training complete. Model written to /root/tfx/pipelines/mnist_native_keras/Trainer.mnist_lite/model/7/serving_model_dir. ModelRun written to /root/tfx/pipelines/mnist_native_keras/Trainer.mnist_lite/model_run/7\n",
            "INFO:absl:Running publisher for Trainer.mnist_lite\n",
            "INFO:absl:MetadataStore with DB connection initialized\n",
            "INFO:absl:Component Trainer.mnist_lite is finished.\n",
            "INFO:absl:Component Evaluator.mnist_lite is running.\n",
            "INFO:absl:Running driver for Evaluator.mnist_lite\n",
            "INFO:absl:MetadataStore with DB connection initialized\n",
            "INFO:absl:Running executor for Evaluator.mnist_lite\n",
            "INFO:absl:Attempting to infer TFX Python dependency for beam\n",
            "INFO:absl:Copying all content from install dir /usr/local/lib/python3.6/dist-packages/tfx to temp dir /tmp/tmpglb0wt6u/build/tfx\n",
            "INFO:absl:Generating a temp setup file at /tmp/tmpglb0wt6u/build/tfx/setup.py\n",
            "INFO:absl:Creating temporary sdist package, logs available at /tmp/tmpglb0wt6u/build/tfx/setup.log\n",
            "INFO:absl:Added --extra_package=/tmp/tmpglb0wt6u/build/tfx/dist/tfx_ephemeral-0.25.0.tar.gz to beam args\n",
            "WARNING:absl:\"maybe_add_baseline\" and \"maybe_remove_baseline\" are deprecated,\n",
            "        please use \"has_baseline\" instead.\n",
            "INFO:absl:Request was made to ignore the baseline ModelSpec and any change thresholds. This is likely because a baseline model was not provided: updated_config=\n",
            "model_specs {\n",
            "  label_key: \"image_class\"\n",
            "  model_type: \"tf_lite\"\n",
            "}\n",
            "slicing_specs {\n",
            "}\n",
            "metrics_specs {\n",
            "  metrics {\n",
            "    class_name: \"SparseCategoricalAccuracy\"\n",
            "    threshold {\n",
            "      value_threshold {\n",
            "        lower_bound {\n",
            "          value: 0.8\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n",
            "INFO:absl:Using /root/tfx/pipelines/mnist_native_keras/Trainer.mnist_lite/model/7/serving_model_dir as  model.\n",
            "INFO:absl:The 'example_splits' parameter is not set, using 'eval' split.\n",
            "INFO:absl:Evaluating model.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:6 out of the last 6 calls to <function recreate_function.<locals>.restored_function_body at 0x7fecfc4db1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:6 out of the last 6 calls to <function recreate_function.<locals>.restored_function_body at 0x7fecfc4db1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "INFO:absl:Evaluation complete. Results written to /root/tfx/pipelines/mnist_native_keras/Evaluator.mnist_lite/evaluation/8.\n",
            "INFO:absl:Checking validation results.\n",
            "INFO:absl:Blessing result True written to /root/tfx/pipelines/mnist_native_keras/Evaluator.mnist_lite/blessing/8.\n",
            "INFO:absl:Running publisher for Evaluator.mnist_lite\n",
            "INFO:absl:MetadataStore with DB connection initialized\n",
            "INFO:absl:Component Evaluator.mnist_lite is finished.\n",
            "INFO:absl:Component ExampleValidator is running.\n",
            "INFO:absl:Running driver for ExampleValidator\n",
            "INFO:absl:MetadataStore with DB connection initialized\n",
            "INFO:absl:Running executor for ExampleValidator\n",
            "INFO:absl:Attempting to infer TFX Python dependency for beam\n",
            "INFO:absl:Copying all content from install dir /usr/local/lib/python3.6/dist-packages/tfx to temp dir /tmp/tmpmjd_v43c/build/tfx\n",
            "INFO:absl:Generating a temp setup file at /tmp/tmpmjd_v43c/build/tfx/setup.py\n",
            "INFO:absl:Creating temporary sdist package, logs available at /tmp/tmpmjd_v43c/build/tfx/setup.log\n",
            "INFO:absl:Added --extra_package=/tmp/tmpmjd_v43c/build/tfx/dist/tfx_ephemeral-0.25.0.tar.gz to beam args\n",
            "INFO:absl:Validating schema against the computed statistics for split train.\n",
            "INFO:absl:Validation complete for split train. Anomalies written to /root/tfx/pipelines/mnist_native_keras/ExampleValidator/anomalies/9/train.\n",
            "INFO:absl:Validating schema against the computed statistics for split eval.\n",
            "INFO:absl:Validation complete for split eval. Anomalies written to /root/tfx/pipelines/mnist_native_keras/ExampleValidator/anomalies/9/eval.\n",
            "INFO:absl:Running publisher for ExampleValidator\n",
            "INFO:absl:MetadataStore with DB connection initialized\n",
            "INFO:absl:Component ExampleValidator is finished.\n",
            "INFO:absl:Component Pusher.mnist_lite is running.\n",
            "INFO:absl:Running driver for Pusher.mnist_lite\n",
            "INFO:absl:MetadataStore with DB connection initialized\n",
            "INFO:absl:Running executor for Pusher.mnist_lite\n",
            "INFO:absl:Attempting to infer TFX Python dependency for beam\n",
            "INFO:absl:Copying all content from install dir /usr/local/lib/python3.6/dist-packages/tfx to temp dir /tmp/tmp_01sfke4/build/tfx\n",
            "INFO:absl:Generating a temp setup file at /tmp/tmp_01sfke4/build/tfx/setup.py\n",
            "INFO:absl:Creating temporary sdist package, logs available at /tmp/tmp_01sfke4/build/tfx/setup.log\n",
            "INFO:absl:Added --extra_package=/tmp/tmp_01sfke4/build/tfx/dist/tfx_ephemeral-0.25.0.tar.gz to beam args\n",
            "INFO:absl:Model version: 1607667210\n",
            "INFO:absl:Model written to serving path /content/drive/MyDrive/Fall_2020/Advanced Deep Learning- CMPE 297- 49/Assignments/Assignment 6_TFX interactivecontext based colab/mnist/serving_model_lite/mnist_native_keras/1607667210.\n",
            "INFO:absl:Model pushed to /root/tfx/pipelines/mnist_native_keras/Pusher.mnist_lite/pushed_model/10.\n",
            "INFO:absl:Running publisher for Pusher.mnist_lite\n",
            "INFO:absl:MetadataStore with DB connection initialized\n",
            "INFO:absl:Component Pusher.mnist_lite is finished.\n",
            "INFO:absl:Component Pusher.mnist is running.\n",
            "INFO:absl:Running driver for Pusher.mnist\n",
            "INFO:absl:MetadataStore with DB connection initialized\n",
            "INFO:absl:Running executor for Pusher.mnist\n",
            "INFO:absl:Attempting to infer TFX Python dependency for beam\n",
            "INFO:absl:Copying all content from install dir /usr/local/lib/python3.6/dist-packages/tfx to temp dir /tmp/tmp68rc1gbl/build/tfx\n",
            "INFO:absl:Generating a temp setup file at /tmp/tmp68rc1gbl/build/tfx/setup.py\n",
            "INFO:absl:Creating temporary sdist package, logs available at /tmp/tmp68rc1gbl/build/tfx/setup.log\n",
            "INFO:absl:Added --extra_package=/tmp/tmp68rc1gbl/build/tfx/dist/tfx_ephemeral-0.25.0.tar.gz to beam args\n",
            "INFO:absl:Model version: 1607667211\n",
            "INFO:absl:Model written to serving path /content/drive/MyDrive/Fall_2020/Advanced Deep Learning- CMPE 297- 49/Assignments/Assignment 6_TFX interactivecontext based colab/mnist/serving_model/mnist_native_keras/1607667211.\n",
            "INFO:absl:Model pushed to /root/tfx/pipelines/mnist_native_keras/Pusher.mnist/pushed_model/11.\n",
            "INFO:absl:Running publisher for Pusher.mnist\n",
            "INFO:absl:MetadataStore with DB connection initialized\n",
            "INFO:absl:Component Pusher.mnist is finished.\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}